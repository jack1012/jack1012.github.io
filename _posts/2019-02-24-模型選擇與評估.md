---
layout      : post
title       : 模型選擇與評估
date        : 2019-02-21 10:41:10 +0800
categories  : 資料處理與分析概論
tags        : [資料分析,機器學習概論,模型選擇與評估]
---

# 模型選擇與評估

## 模型績效評量
機器學習過程中將資料切分成訓練子集(training set)和測試子集(testing set)，訓練子集用來建立模型，測試子集用於評估模型績效表現。

- 配適不足：測試誤差高，訓練誤差高
- 過度配適：測試誤差高，訓練誤差低
- 配適良好：測試誤差低，訓練誤差低
- 配適不明：測試誤差低，訓練誤差高

#### 練習題
B 14. 當資料科學家建模時，如果有測試誤差高，訓練誤差低的狀況時，稱為下列何者？
(A) 配適不足
(B) 過度配適
(C) 配適良好
(D) 配適狀況不明

244 配適不足
C 244. 關於配適不足（ under-fitting），下列何者正確？
(A) 訓練誤差較大，測試誤差較小
(B) 訓練誤差較小，測試誤差較大
(C) 訓練誤差較大，測試誤差較大
(D) 訓練誤差較小，測試誤差較小


47Overfitting
D 47. 下列哪種方法可以避免機器學習模型過度配適（ Overfitting）？
(A) 選擇特徵（ Feature Selection）
(B) 交叉驗證（ Cross Validation）
(C) 對目標函數施加懲罰（ Penalty）
(D) 以上皆是


145 過度擬合
A 145. 下列何者為「學習模型時，為了得到好的準確度」而容易造成的問題？
(A) 過度擬合（ Overfitting）
(B) 資料標籤不均（ Imbalanced Data）
(C) 資料維度過高
(D) 資料集過大

41模型評估
C 41. 模型複雜度與預測誤差之間的變化關係，通常是越複雜的模型與訓練集合配適的越好。因此，一般而言訓練集的預測誤差，會隨著模型複雜度如何變化？
(A) 增加而增加
(B) 減少而減少
(C) 增加而減少
(D) 減少而增加

45過度擬合
A 45. 在進行機器學習時，下列何者「不是」避免過度配適（ overfitting） 的方法？
(A) 減少資料量
(B) 減少模型參數
(C) 使用較簡單的模型
(D) 在損失函數（ loss function） 加入參數權重的 L2 norm，抑制權重變大


### 迴歸模型績效指標
- 誤差平方和(SSE)
- 誤差絕對值和(SAE) ：是預期值與實際值之間的相對絕對差值；相對是因為會將平均值差除以算術平均值。
- 平均絕對誤差 (MAE)： 會測量預測與實際結果的接近程度；因此，分數越低越好。
- 誤差的標準差(SEP)
- 均方預測誤差(MSE)
- 相對平方誤差 (RSE) ：同樣會將預測值的總平方誤差除以實際值的總平方誤差來將預測值的總平方誤差正規化。
- 均方根預測誤差(RMSE)： 會建立單一值來彙總模型中的錯誤。 藉由將差值平方，此計量可忽略預測過頭和預測不足之間的差異。
- 判定係數(R^2)：可用 0 與 1 之間的值來表示模型的預測能力。 0 表示模型是隨機的 (無法說明任何事)；1 表示有完美的配適。 不過，請小心解讀 R2 值，因為較低的值可能是完全正常，較高的值則很可疑。
- 赤池宏次訊息準則(AIC)
- 舒瓦茲貝式訊息準則(BIC)

#### 練習題
45判定係數
B 45. 如果判定係數為 0.8，則依變數能被自變數解釋的變異百分比為？
(A) 0.8%
(B) 80%
(C) 0.64%
(D) 不一定

95Overfitting
C 95. 關於過度配適（ Overfitting），下列敘述何者不正確？
(A) 知識發掘的方法在建立模型的過程中容易出現過度配適的情形，模型可能陷入只能解釋在訓練集樣本的關聯，而沒辦法一體適用
(B) 機器學習所學到的假設（ Hypothesis）過度貼近訓練資料（ TrainingData），而導致測試資料（ Testing Data）錯誤率變得更大
(C) 過度配適表示測試資料的正確率極高
(D) 為了避免過度配適現象，必須使用額外的技巧，如交叉驗證、 EarlyStopping、貝斯信息量準則（ BIC）、赤池信息量準則（ AIC）等

149 線性迴歸模型評估
B 149. 關於線性迴歸模型績效評估，下列敘述何者不正確？
(A) 評估模型績效的方式不只一種
(B) 通常可透過混淆矩陣評估模型績效
(C) 殘差繪圖（ Residual Plots）是以視覺化的方式檢視模型的配適狀況
(D) 許多績效評量的計算是基於殘差（ Residual），它是各觀測值減去其模型的預測值，而常用的 SSE 是殘差平方的總和

174 迴歸分析(判定係數)
D 174. 請參考以下迴歸分析結果：
下列敘述何者正確？
(A) 模型不具有線性模型解釋能力
(B) 模型的截距為 3.45000
(C) 模型的樣本數為 13
(D) 模型的判定係數（ Coefficient of Determination）為 0.991

199 模型績效評估
D 199. 關於迴歸模型績效評估，下列敘述何者正確？
(A) 評估模型績效的方式不只一種，通常只用一種模型績效評估的方式來決定模型的優劣
(B) 許多績效評量的計算是基於殘差（ residual），它是模型的預測值減去觀測值
(C) 常用的績效評量 SSE 是殘差平方的平均值，而另一個常用的績效評量 MSE 是殘差平方的總和
(D) R2 也是常用的績效評量，其值表示資料中的訊息被模型所解釋的比例， R2 的解釋與結果變數的變異有關

46AIC BIC模型判定
A 46. 下方表格是針對同一份資料建立的四種複迴歸模型， 根據各種模型之
指標資訊， 請問下列何者為最佳模型？
模型編號 模型 AIC BIC Cp R2
模型 1 -55 50 3 0.8
模型 2 -55 50 4 0.8
模型 3 -30 60 3 0.8
模型 4 10 100 3 0.8
AIC 為赤池信息量準則（ Akaike Information Criterion）；
BIC 為貝葉斯信息準則（ Bayesian Information Criterion）；
Cp 為馬洛斯 Cp（ Mallows’Cp）；
R2 為判定係數（ coefficient of determination）
(A) 模型 1
(B) 模型 2
(C) 模型 3
(D) 模型 4

B 12. 真實的反應變數值與預測的反應變數值之間的差，稱為殘差或（預測）誤差，下列何者是應用殘差平方值的算術平均來評估迴歸模型的績效？
(A) 誤差平方和（ Sum of the Squared Errors, SSE）
(B) 均方預測誤差（ Mean Squared Error , MSE）
(C) 均方根預測誤差（ Root Mean Squared Error, RMSE）
(D) 誤差絕對值和（ Sum of Absolute Error, SAE）

### 分類模型績效指標
- 混淆矩陣
- 正確率、錯誤率：會測量分類模型的健全情況，表現方式為 True 結果對整體案例的比例。
- kappa統計量
- 召回率( Recall)：是 True 結果對所有正面結果的比例。 Precision = TP/（TP + FP）
- 精準度(Percision)：是實際抓取的相關實例總數的分數。 召回 = TP/（TP + FN）
- F-measure：F1 分數：會計算為精確度的加權平均值，並在0和1之間重新叫用，其中理想的 F1 分數值是1。
- ROC曲線
- AUC：會測量透過 y 軸上的正判和 x 軸上的誤判繪製出的曲線下的區域。 此計量十分有用，因為其會提供單一數字來讓您比較不同類型的模型。


#### 練習題
46Confusion Matrix
C 46. 假設在一混淆矩陣（ Confusion Matrix）中，真陽性（ True positive）為100，假陽性（ False Positive）為 50，真陰性（ True Negative）為 50，假陰性（ False Negative）為 800，請問該混淆矩陣的準確度（ Accuracy）為？
(A) 0.6667
(B) 0.9412
(C) 0.15
(D) 0.84

97Confusion Matrix
C 97. 假設在一混淆矩陣（ Confusion Matrix）中，真陽性（ True Positive）為 100，假陽性（ False Positive）為 50，真陰性（ True Negative）為 50，假陰性（ False Negative）為 800，請問該混淆矩陣的真陽性率（ True Positive Rate）為？
(A) 0.15
(B) 0.9
(C) 0.6667
(D) 0.1

50混淆矩陣
D 50. 關於二元分類（ binary classification），若一分類模型產生之混淆矩陣（ confusion matrix） 如下，該模型之精確度（ precision） 為下列何者？
|---------|-True-|- False-|
 |True |8 |3|
 |False |12| 11|
(A) 3/11
(B) 8/20
(C) 19/34
(D) 8/11

38混淆矩陣
C 38. 對於二元分類問題，依真實資料的真假值與模型預測輸出的真假值，可以組合出真陽性（ True Positive, TP）、真陰性（ True Negative, TN）、偽陽性（ False Positive, FP）、偽陰性（ False Negative, FN） 四種情況，組成混淆矩陣（ Confusion matrix）。若模型追求較高的精確率（ precision），則應提高下列何者？
(A) TP
(B) TN
(C) TP/(TP+FP)
(D) TP/(TP+FN)

C 16. 有一個混淆矩陣（ confusion matrix），橫列表示預測類別，縱行表示真實類別，假設有一個預測類別矩陣為[0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1 ,1]，真實類別矩陣為[1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0 ,1]， 則假陽數（ false positive）的值為何？
(A) 3
(B) 5
(C) 2
(D) 6



44ROC
C 44. 關於下方接收者操作特性曲線（ Receiver Operating Characteristic Curve,ROC） 圖，下列敘述何者正確？
(A) 假陽率（ false positive rate）數值愈大表示分類較準確
(B) 真陽率（ true positive rate）數值愈大表示分類較不準確
(C) 支援向量機（ Support Vector Machine, SVM） 模型分類準確率較類神經網路（ Neural Network, NN） 模型為佳
(D) 上述接收者操作特性曲線無法判斷支援向量機（ Support Vector Machine, SVM） 模型或類神經網路（ Neural Network, NN） 模型的分類準確率


B 10. 關於接收者操作特性曲線（ Receiver Operating characteristic Curve, ROC），下列敘述何者「 不」 正確？
(A) ROC 曲線往左上角移動，代表模型的敏感度越高
(B) AUC=0.8，代表無鑑別力
(C) ROC 常用於分析二元分類模型
(D) ROC 曲線是以假陽性率（ False Positive Rate, FPR） 為 X 軸，以真陽性率（ True Positive Rate, TPR） 為 Y 軸

D 9. 下列何者「 不是」 用來評估模型的驗證指標（ validation index） ？
(A) 均方誤差（ Mean Squared Error, MSE）
(B) 混淆矩陣（ confusion matrix） 與敏感度（ sensitivity）
(C) ROC 曲線與曲線下方面積（ Area Under Curve, AUC）
(D) 特徵值（ eigenvalue）

### 群集模型
針對群集模型傳回的統計資料會描述指派給每個叢集的資料點數目、叢集之間的分隔量，以及每個叢集內資料點的緊密程度。

群集模型的統計資料會取整個資料集的平均值，並會有額外的資料列包含每一叢集的統計資料。

系統會報告下列計量以供評估群集模型：
- 與其他中心的平均距離：資料行中的分數，表示叢集中的每個點與所有其他叢集的距心接近程度平均值。
- 與叢集中心的平均距離：資料行中的分數，表示叢集中的每個點到該叢集距心的接近程度。
- 點數：資料行會顯示指派給每個叢集的資料點數量，以及任何叢集中的資料點整體總數。
  - 如果指派給叢集的資料點數目小於可用的資料點總數，則表示無法將資料點指派給叢集。
- 與叢集中心的最大距離：資料行中的分數代表每個點和該點的叢集距心之間的距離上限。
  - 如果這個值很高，就可能表示叢集分散很廣。 您應該將此統計資料與叢集中心的平均距離放在一起檢閱，以判斷叢集的散佈。
- 合併評估分數：結果的每個區段底部其會列出該特定模型中所建立叢集的平均分數。


## 模型選擇與評定
- 模型選擇：或稱模型優化，包括同一模型的不同參數調校，以及不同模型的比較。
- 模型評定：未來績效評估，在確定最後模型後，合理地估計其未來實際應用上的績效表現。

以上兩種都需要搭配多種訓練與測試的機制，各種訓練與測試的機制差別在於運用不同的抽樣或重抽樣策略，挑選訓練集、驗證集、測試集。

訓練集：用以建立模型
驗證集：用以調校模型參數，是預測評估模型配適（ fitting） 度及尋找模型參數的方法
測試集：合理估計模型未來績效

### 抽樣方式
- 重抽樣：重抽樣是反覆地從訓練集或資料集中抽出或有不同的各組樣本，並重新配適各組樣本的模型，以獲得模型相關的額外資訊
  - 拔靴抽樣：多次置回的方式，從未被取到的樣本稱為帶外樣本(1/e=約36.8%)
  - k摺交叉檢驗：若 k=10，代表將數據集分成 10 份，將其中 9 份做訓練、 1 份做驗證。相較於他法有較高的變異，但當訓練集大時則此問題較不嚴重
    - 重複的k摺交叉驗證可以有效提高估計的精確度，同時保持小的偏誤，不過計算工作相當沉重
- 保留法：避免使用相同的資料來訓練模型與測試
  - 樣本充足：訓練集、驗證集、測試集
  - 樣本較少時：校驗集(calibration)、測試集
  - 雙重重抽樣，先交叉驗證將資料切割分成校驗集與測試集(外圈重抽樣)；對各校驗集運行交叉驗證進行模型最佳化程序；回到外圈以測驗集估計最佳化模型的績效表現。


#### 練習題
D 15. 模型選擇與評定時，經常運用重抽樣方法進行模型訓練與測試，下列敘述何者正確？
(A) 模型評定（ model assessment） 的工作包括同一模型不同參數的調校（ within model），以及跨越不同模型的比較（ between models）
(B) 模型優化（ model optimization） 的工作則是在確定最優模型後，合理地估計其未來實際應用上可能的績效表現
(C) 與隨機誤差建模相關的參數（ parameters） 有兩種： 一種可以直接利用資料估計其值的超參數（ hyperparameters），另一種則是不易從資料中估計的模型參數
(D) 一般而言 k 摺交叉驗證（ k-fold cross validation） 相較於他法有較高的變異，但當訓練集大時則此問題較不嚴重


143 訓練集與測試集
A 143. 關於訓練資料集與測試資料集，下列敘述何者正確？
(A) 訓練資料是從要分析的資料庫中隨機取樣
(B) 訓練資料可以不知道其類別
(C) 測試資料可以包含訓練資料集中的資料
(D) 測試資料可以不知道其類別


49交叉驗證
B 49. 關於機器學習中的交叉驗證（ Cross-Validation），下列敘述何者正確？
(A) 使用不同架構的模型在相同的資料上，以驗證訓練效果
(B) 是預測評估模型配適（ fitting） 度及尋找模型參數的方法
(C) 用來避免配適不足（ underfitting）
(D) 將資料分割成訓練集（ training set） 跟測試集（ testing set），進行訓練與分析

50模型訓練與測試機制
D 50. 關於模型訓練與測試機制中的資料切分，下列敘述何者「不正確」？
(A) 實務上常用重抽樣法進行模型最佳化
(B) 決定最佳的模型複雜度或參數組合後，最後再以整個校驗集（ calibration set） 建立最佳複雜度或最佳參數組合下的最終模型
(C) 雙重重抽樣法包含內外兩圈的重抽樣機制，分別負責模型最佳化與績效估計的工作，如此內外圈反覆執行所需計算量應是負擔最重的訓練與測試機制
(D) 生醫或化學計量學等領域常因所搜集到樣本通常較少，因而採行50%的訓練集（ training set）用以建立模型， 25%的驗證集（ validationset） 進行模型參數最佳化，以及 25%的測試集（ test set） 測試最終模型等三個子集的切分方式

26重抽樣
D 26. 關於重抽樣方法（ resampling methods），下列敘述何者「不正確」？
(A) 重抽樣是反覆地從訓練集或資料集中抽出或有不同的各組樣本，並重新配適各組樣本的模型，以獲得模型相關的額外資訊
(B) 常用的重抽樣方法有拔靴抽樣法（ bootstrapping）與 k 摺交叉驗證（ k-fold cross validation）
(C) 交叉驗證（ cross validation） 與拔靴抽樣（ bootstrapping） 兩種方法的差別只在於樣本子集如何被挑出
(D) 一般而言 k 摺交叉驗證（ k-fold cross validation） 相較於他法有較低的變異，但當訓練集大時則此問題較不嚴重

C 13. 交叉驗證（ cross-validation） 主要用於模型訓練或建模應用中，目的是為了得到可靠穩定的模型。請問下列敘述何者「 不」 正確？
(A) k 摺交叉驗證（ k-fold cross validation），若 k=10，代表將數據集分成 10 份，將其中 9 份做訓練、 1 份做驗證
(B) 交叉驗證經常用於分類預測、偏最小平方迴歸（ Partial Least Squares regression， PLS 迴歸） 建模等
(C) 採用 k 摺交叉驗證（ k-fold cross validation） 通常會重複 k 次以上， 以 k-1 次的結果均值作為對算法精度的估計
(D) 交叉驗證的類型，常見的有保留法（ holdout） 驗證、 k 摺驗證

A 8. 分類問題當不同類的樣本數不平衡時，下列何者「 不是」 處理方式？
(A) 使用丟棄（ dropout） 方法從大類中剔除一些樣本
(B) 使用降抽樣（ undersampling） 方法從大類中選取部分樣本
(C) 使用權重（ weighting） 方法調整樣本權重
(D) 使用數據合成（ synthetic） 方法生成新的樣本


### 模型參數調校
- 一般參數：模型上的參數
- 超參數：在訓練前就設定好，例如學習率
  - one-SE法則：一倍標準誤法則，依據全域最佳解下的預測誤差平均值與標準誤(一倍標準誤)之和，挑選預測誤差平均值不超過此門檻的最簡模型。


#### 練習題
A 11. 與隨機誤差建模相關的參數有模型參數和超參數（ hyperparameters），下列何者「 不是」 超參數？
(A) 迴歸方程式的截距
(B) 支援向量機中徑向基底核函數的 σ
(C) 人工神經網路的隱藏層節點數
(D) 建構迴歸方程式的預測變數集

C 197. 梯度遞減法（ Gradient Descent）是機器學習中常使用的參數收斂方式，我們可以透過參數 alpha 來調整整體收斂的速度（ Step Size），請問如果 alpha 過大時，會導致什麼狀況發生？
(A) 太快收斂
(B) 收斂速度過慢
(C) 無法收斂
(D) 以上皆有可能發生

### 比較不同類模型
- 假說檢定的p值


## 相似性與距離
- L^p norm
- 餘弦相似度

## 相關與獨立
### 相關性
- 散佈圖矩陣
- 共變異數
- 相關係數
- 共線性、多重共線性
- 皮爾森相關係數：用來呈現連續型(continous)變數之間的關聯性，尤其在變數符合常態分配的假設下，最爲精確
- 史皮爾曼(Spearman)相關係數：兩個順序尺度類別變數之排名計算相關係數。
  - 相關則不需符合常態，僅要求變數的資料型態至少爲有序的(ordinal)。
  - Spearman相關不受離群值的影響(這是因爲Spearman相關是以排序值(rank)來計算相關係數！)

### 獨立統計
- 如果隨機變數X與Y獨立，則X與Y的共變異數Cov(X,Y)=0，反之不亦然，只能說無線性關係。
- 關聯指標：名目尺度類別變數間的關係強度
- 平均列聯係數
- Cramer指數
- 濾網圖：高維度列聯表視覺化工具
- 馬賽克圖
- 四重圖：對勝率比可視化做關聯檢驗
- 辛普森悖論：在某些條件下的多組數據於分別討論時都會滿足某種性質（例如：A 優於B），但若是直接將數據合併在一起討論時卻可能導致相反的結論（例如：B 優於 A）。



### 分佈類型
25連續型變數
D 25. 下列何者屬於連續型變數資料？
(A) 身分證號
(B) 生日
(C) 血型
(D) 體重


28連續型機率分配
D 28. 統計資料分為離散型與連續型，請問下列何項與其他不同？
(A) 體重
(B) 身高
(C) 成績
(D) 國家數目

29連續型機率分配
D 29. 關於連續型機率分配， 下列敘述何者正確？
(A) 常態分配中， 平均值為 0、 變異數為 0 之分配， 稱為標準常態分配
(B) 已知均勻分配為 U(a, b)，則平均值為(a-b)/2
(C) 伽碼分配是指數分配的特例
(D) 已知隨機變數為標準常態分配，則取其平方為卡方分配且自由度為 1


121 卡方分配、F分配、T分配比較
121. 關於卡方分配、 F 分配、 t 分配之比較，下列敘述何者不正確？
(A) 皆為小樣本
(B) 皆為不連續分配
(C) 三者皆有自由度
(D) 皆來自於常態母體

122 卜瓦松分配
C 122. 關於卜瓦松分配之特性，下列敘述何者不正確？
(A) 某一時段內發生的次數與其他時段發生的次數相互獨立
(B) λ 與所選擇之時間長度成比例
(C) 在極短時間內成功兩次以上之機率不可忽略不計
(D) 在相同長度的時段內發生事件的機率皆相同

124 偏態分佈
B 124. 下圖為海藻資料集的變數 Chla 分佈狀況，請問最接近何種機率分佈？
(A) 常態分佈
(B) 偏態分佈
(C) 幾何分佈
(D) 均勻分佈

171 卡方分配
C 171. 關於卡方分配（ Chi-squared Distribution），下列敘述何者不正確？
(A) 卡方分配的曲線為非對稱的
(B) 卡方分配的期望值為其自由度
(C) 卡方分配的期望值與變異數相等
(D) 卡方分配的自由度越大會使其變異數越大

28機率分配
B 28. 下列敘述何者「不正確」？
(A) 理論上常態分配的平均數=中位數
(B) 機率分配中所有事件機率的總和=期望值
(C) p=0.5 的二項分配為對稱型
(D) 卜瓦松分配中事件發生的最小次數為 0

29常態分佈
C 29. 假設隨機變數 X1、 X2 獨立，且遵從相同的常態分佈 N(μ,σ^2)。若Y=(X1+X2)/2， 請問 Y 遵從的分佈為下列何者？
(A) N(μ,2σ^2)
(B) N(2μ,σ^2)
(C) N(μ,σ^2/2)
(D) N(μ/2,σ^2)
