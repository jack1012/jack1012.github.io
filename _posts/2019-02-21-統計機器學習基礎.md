---
layout      : post
title       : 統計機器學習基礎
date        : 2019-02-21 10:41:10 +0800
categories  : 資料處理與分析概論
tags        : [資料分析,機器學習概論,統計機器學習基礎]
---

# 2-1 統計機器學習基礎

## 機器學習是什麼？

機器學習是賦予電腦能力去學習，這個能力不是明確的程式設計好的。(所謂明確的程式，例如：設計因數分解過程的程式，讓電腦判斷一個數是否為質數)
- Field of study that gives computers the ability to learn without being explicitly programmed. (Arthur Samuel, 1959)

練習題：設計一個機器學習模型來學習判斷給定的正整數字是否為偶數

所謂的電腦程式從一些任務(T)中的經驗(E)和表現(P)學習，是指它(電腦程式)在這些任務(T)的表現(P)隨著經驗(E)而改善。
- A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P,improves with experience E. (Tom Mitchell, 1998)

舉例：電腦從許多下圍棋的經驗(E)結果勝或負(P)來學習下西洋棋(T)這個任務，在電腦程式下圍棋的任務中透過下棋的經驗來得到更好的表現。

換句話說，電腦在特定任(T)透過不斷的經驗(E)與結果(P)來學習。

用資料科學的語言來說，機器學習是電腦程式，處理特定問題(分類問題、迴歸預測問題、分群問題...等等)，透過不斷處理資料輸出結果，不斷的從這過程中去自動修正程式中的參數，改善電腦程式對於這個特定問題的表現。

從數學的角度來看，機器學習本質上是應用統計的一種形式，著重於使用電腦來估計複雜函數，過程中用到許多統計的知識，例如：隨機誤差、最大概似估計、抽樣...等等。


### 統計機器學習模型
機器學習就是假設隨機誤差模型來希望從資料中將隱含且不精確的函數關係學習出來。以建立反應變數(response variable) $y$ 與多個預測變數(predictor variables) $x_1, x_2,\cdots, x_m$ 之間的模型，而隨機誤差(random error)模型，或稱機率(probabilistic)模型，是機器學習的基本假設：
$$y = f(x_1,x_2,\cdots,x_m) + \epsilon$$
其中 $\epsilon$ 是隨機誤差，所以 $y$ 也是隨機變數。

### 機器學習的目標
目前許多機器學習的模型能夠建立非常複雜的模型，然而複雜的模型容易過度強調訓練樣本中未來不會重複出現的型態，因而產生過度配適(overfitted)的模型。因此，我們需要一套評估是否過度配適的指引方針，避免陷入過度配適的危機。


### 模型績效評量
機器學習過程中將資料切分成訓練子集(training set)和測試子集(testing set)，訓練子集用來建立模型，測試子集用於評估模型績效表現。

- 配適不足：測試誤差高，訓練誤差高
- 過度配適：測試誤差高，訓練誤差低
- 配適良好：測試誤差低，訓練誤差低
- 配適不明：測試誤差低，訓練誤差高

#### 練習題
B 14. 當資料科學家建模時，如果有測試誤差高，訓練誤差低的狀況時，稱為下列何者？
(A) 配適不足
(B) 過度配適
(C) 配適良好
(D) 配適狀況不明

244 配適不足
C 244. 關於配適不足（ under-fitting），下列何者正確？
(A) 訓練誤差較大，測試誤差較小
(B) 訓練誤差較小，測試誤差較大
(C) 訓練誤差較大，測試誤差較大
(D) 訓練誤差較小，測試誤差較小


47Overfitting
D 47. 下列哪種方法可以避免機器學習模型過度配適（ Overfitting）？
(A) 選擇特徵（ Feature Selection）
(B) 交叉驗證（ Cross Validation）
(C) 對目標函數施加懲罰（ Penalty）
(D) 以上皆是


145 過度擬合
A 145. 下列何者為「學習模型時，為了得到好的準確度」而容易造成的問題？
(A) 過度擬合（ Overfitting）
(B) 資料標籤不均（ Imbalanced Data）
(C) 資料維度過高
(D) 資料集過大

41模型評估
C 41. 模型複雜度與預測誤差之間的變化關係，通常是越複雜的模型與訓練集合配適的越好。因此，一般而言訓練集的預測誤差，會隨著模型複雜度如何變化？
(A) 增加而增加
(B) 減少而減少
(C) 增加而減少
(D) 減少而增加

45過度擬合
A 45. 在進行機器學習時，下列何者「不是」避免過度配適（ overfitting） 的方法？
(A) 減少資料量
(B) 減少模型參數
(C) 使用較簡單的模型
(D) 在損失函數（ loss function） 加入參數權重的 L2 norm，抑制權重變大

### 機器學習類型
- 監督式學習：迴歸建模、分類模型
- 非監督式學習：集群、關聯、降維
- 半監督式學習：自我訓練、修正集群
- 強化式學習：馬可夫決策過程
- 薈萃式學習
- 深度學習

#### 練習題

250 資料解析思維
B 250. 關於資料解析思維，下列敘述何者不正確？
(A) 巨量資料中雜訊多，穩健統計方法可降低雜訊對模型的影響
(B) 機器學習模型不需要考慮資料是否與背景假設吻合
(C) 利用重抽樣樣本中的不確定性，可以強化參數估計過程與避免過度配適
(D) 集成（或稱系集）模型（ ensemble models）可以發揮團結力量大的效果，解決困難的問題

150 資料解析思維
A 150. 關於資料解析思維，下列敘述何者不正確？
(A) 資料建模時，規範性（ Prescriptive）模型、敘述性（ Descriptive)模型與預測性（ Predictive） 模型必須謹慎擇一使用
(B) 許多資料建模方法成功的關鍵是決定合宜的接近性衡量，以同中求異、異中求同的思維解決問題
(C) 資料前處理就是避免垃圾進垃圾出（ Garbage In Garbage Out, GIGO）
(D) 不確定型態建模時須以合宜的理論（ Theoretical）機率分佈，捕捉實際資料之經驗（ Empirical）機率分佈變異的型態

C 32. 下列技術之應用，何者最「 不」 適當？
(A) 用卷積網路（ Convolutional Neural Networks, CNN） 辨識影像內容
(B) 用遞歸網路（ Recurrent Neural Networks, RNN） 進行文字翻譯
(C) 用 k 平均數演算法（ k-means） 學習多分類問題
(D) 用自動編碼器（ autoencoder） 將資料降維
