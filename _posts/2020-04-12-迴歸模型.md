---
layout      : post
title       : 迴歸模型
date        : 2020-04-12 10:41:10 +0800
categories  : 進階機器學習
tags        : [機器學習,線性迴歸,多元線性迴歸]
---

# 迴歸模型

目的在於找出一條最能夠代表所有觀測資料的函數（迴歸估計式）。用此函數代表因變數(反應變數)和自變數(預測變數)之間的關係，也就是隨機誤差(random error)模型$E(y | x_1,x_2,\cdots,x_m) = f(x_1,x_2,\cdots,x_m)$ 。其中反應變數 $y$ 為數值的。

參數估計方法：
- 矩估計（Method of Moment、MOM）
- 最小平方法（Ordinary Least Square Estimation, OLSE）
- 最大似然估計（Maximum Likelihood Estimation, MLE）

當反應變數 $y$ 呈現兩種或兩種以上的形式或類別，此時我們要建立分類模型。


# 各類迴歸
- 線性迴歸
  -  簡單線性迴歸(OLS)
  -  多元線性迴歸
- 偏最小平方法迴歸(PLS)
- 脊迴歸
- 套索迴歸(LASSO)

## 進階討論

1. 迴歸分析的基本統計假設：
- 依變數和自變數之間的關係必須是線性
- 資料呈現常態分配（Normal Distribution）
- 自變數的誤差項，相互之間應該是獨立的

2. 各類分析方法
- 當自變項為「連續」，依變項為「連續」，可採用相關分析、簡單/多元迴歸分析、路徑分析等。
- 當自變項為「連續」，依變項為「不連續」，可採用羅吉斯分析、區別分析等。
- 當自變項為「不連續」，依變項為「連續」，可採用獨立/相依t檢定、變異數分析、共變數分析等。
- 當自變項為「不連續」，依變項為「不連續」，可採用描述性統計分析、卡方檢定等。
![自變項與依變項的測量尺度的關係圖](scale2-1.png)

3. 關於迴歸模型績效評估，下列敘述何者正確？D
- (A) 評估模型績效的方式不只一種，通常只用一種模型績效評估的方式來決定模型的優劣
- (B) 許多績效評量的計算是基於殘差（residual），它是模型的預測值減去觀測值
- (C) 常用的績效評量SSE是殘差平方的平均值，而另一個常用的績效評量MSE是殘差平方的總和
- (D) R2也是常用的績效評量，其值表示資料中的訊息被模型所解釋的比例，R2的解釋與結果變數的變異有關

4. 關於迴歸模型，下列敘述何者 「不正確」 A
- (A) 可用來解釋資料現象間的因果關係
- (B) 利用自變數來預測依變數未來可能產生之值
- (C) 視其函數之型態分為線性與非線性
- (D) 根據自變數個數可分為簡單迴歸分析( simple regression analysis) 及複迴歸分析( multiple regression analysis)

5. 逐步迴歸選擇重要的變數進行建模：
- 後向式：需傳入完整模型，再逐次剔除不重要變數，建模時間長，逐步迴歸過程AIC或BIC值越小，模型適配的越好。
- 前向式：從只有截距項的最簡單模型出發，逐步加入變數，當模型不再有顯著改善時完成變數選取。(以變數係數顯著水準低於5%作為選取門檻)
- 最後將兩種方式所得到的模型以ANOVA進行F檢定，對立假設後向式模型比前向式模型好，若檢定結果有顯著則則選擇後向式模型。最終再與完整模型進行檢定比較。

6. 當預測變數的個數 $m$ 大於觀測值個數 $n$ 時，OLS的迴歸係數有多重解。有兩種方法處理：
- 移除高度相關的預測變數
- 非監督式降維：PCA，對預測變數進行降維處理。容易使的預測變數的實際意義不易理解，降低模型的可解釋性。
- 監督式的降維：PLS，通過投影預測變數和觀測變數到一個新空間來尋找一個線性迴歸模型。因為數據X和Y都會投影到新空間，PLS系列的方法都被稱為雙線性因子模型。

參考閱讀 <https://www.yongxi-stat.com/sem-pls/>
