---
layout      : post
title       : 進階機器學習
date        : 2020-04-02 10:41:10 +0800
categories  : 進階機器學習
tags        : [機器學習,簡介]
---

# 進階機器學習
在機器學習領域，對模型的評估非常的重要，只有選擇與問題相匹配的評估方法，才能更好的模型訓練和模型選擇的時候出現的問題，才能更好的對模型進行疊代優化。

原文網址：<https://kknews.cc/code/4x39xzg.html>

然而，機器學習基於統計學的框架，模型假設為一個 [隨機誤差模型]({% post_url 2020-04-03-隨機誤差模型 %})，希望從資料中將隱含且不確定性的關係學習出來，因此機器學習涉及數據，而數據必須基於統計學框架來進行[描述與評估]({% post_url 2020-04-10-模型績效評估%})，進而自動化執行[作業最佳化任務]({% post_url 2020-04-11-模型最佳化%})。

隨著機器學習應用在大數據分析與人工智慧上，越來越多的實務經驗告訴我們一些特定的工作使用特定的模型會有較佳的結果，例如：CNN 善於處理空間上連續的資料，例如影像辨識；RNN 適合處理有時間序列、語意結構的資料，例如分析 ptt 電影版的文章是好雷或負雷；而 GAN 生成器 (generator) 與鑑別器 (discriminator) 的對抗訓練模式可以輔佐電腦「觀全局」。

目前也有許多關於機器學習模型的選擇，基本上多是基於處理的問題來選擇，以下提供幾個參考的指引
<https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html>

<https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-cheat-sheet>

## 機器學習分類

- 監督式學習：在建構 $E(y \lvert x_1,x_2,\cdots,x_m)=f(x_1,x_2,\cdots,x_m)$ 的關係時，學習目標 $y$ 是明確的。$y$ 為數值時，稱為監督式學習的迴歸(regression)建模；$y$ 為類別變數時，則是監督式學習的分類(classification)模型。

- 非監督式學習：在學習目標 $y$ 明確時或暫時忽略，對於建構的模型或關係不確定，或是事先不知道那些預測變數有用，僅在預設變數空間中採行群集、關聯、降維等分析與探索手法。

- 半監督式學習：融合前述兩種學習方式，交叉運用有類別標籤與無類別標籤的訓練樣本來建立預測模型。一般而言，有兩種類型的半監督式學習：
  - 迭代式自我訓練：運用無標籤訓練樣本的資訊，改善標準監督式分類的績效。
  - 半監督式群集：藉由有標籤的訓練樣本形成的必連與必分限制，融入群集算法的距離或相似性計算準則，據以形成集群。換句話說，就是運用標籤樣本的資訊，修正集群算法的目標函數。

- 強化式學習：涉及序列相關的決策，此類決策的解題基本思想非常簡單，將循序決策的大問題分解成不同但相關的子問題，一一解決子問題後再合併它們的解即可得出原問題的解。馬可夫決策過程式重要的解法之一，常用來解決西洋棋或象棋對弈的問題。

-  薈萃式學習：著眼於不同分類模型的特質，及對訓練資料中隨機噪訊的不同敏感程度，集合多個同類或不同類模型的預測結果，期望總結出來的預測值能夠準確命中目標。

-  深度學習：具備多層隱藏層的各式類神經網絡，透過各隱藏層中的神經元，對前層傳遞來的預測變數或潛在屬性，進行深層的特徵萃取、知識發現與型態辨識等地挖掘。

## 十大機器學習算法

-  線性迴歸 LINEAR REGRESSION
-  邏輯迴歸LOGISTIC REGRESSION
-  線性判別分析LINEAR DISCRIMINANT ANALYSIS
-  分類與迴歸樹CLASSIFICATION AND REGRESSION TREES
-  天真貝氏NAIVE BAYES
-  K近鄰K-NEAREST NEIGHBORS
-  學習式向量量化LEARNING VECTOR QUANTIZATION
-  支援向量機SUPPORT VECTOR MACHINES
-  隨機森林BAGGING AND RANDOM FOREST
-  自適應增強BOOSTING AND ADABOOST
