---
layout      : post
title       :   K近鄰法
date        : 2020-04-19 10:41:10 +0800
categories  : 進階機器學習
tags        : [機器學習,分類模型, K近鄰法]
---

#  K近鄰法
 K近鄰法是在預測變數空間中，決定新樣本最接近的 $k$ 位訓練集鄰居，以其目標變數值 ${y_1, \cdots, y_k}$的多數決結果(當 $y_i$ 是類別標籤時)，或者是中位數、算數平均數等計算結果(當 $y_i$ 為數值變數時)，進行心樣本的分類或迴歸預測。

## K近鄰法的核心
 K近鄰法的基本運作方式，是以樣本的距離為此運算的核心，常用的距離定義有以下幾類：
 - $L_1$ 與 $L_2$ 範數
 - Tanimoto距離
 - Hamming距離
 - cosine相似度

## K近鄰法注意事項
 1. K近鄰法運用時要留意預測變數的尺度(必要時做尺度均一化)，和遺缺值的影響(刪除不完整的觀測值或添補遺缺值)。

 2. 近鄰個數 $k$ 是待調參數，$k$ 小容易過度配適，$k$ 大時則容易配適不足。

 3. K近鄰法計算耗時，計算時須將數據載入記憶體中，當資料量大時通常用節省記憶體的資料結構以加快計算，例如 $k$ 維樹(k-dimensional tree)

 4. K近鄰法其實並未配適任何模型，它只是把訓練樣本儲存起來，進行死記硬背的學習(rote learning)，所以K近鄰法又有一個有趣的名稱叫懶惰學習(lazy learning)。

 ## K近鄰法的特點：
 - 原理簡單但有效
 - 不須對資料有任何分佈上的假設
 - 訓練過程快速，其實應該是沒有訓練過程，或者說訓練過程一次完成
 - 因為沒有模型，所以限制了我們了解預測變數與目標變數之間的關係能力
 - 需要選擇適合的 $k$
 - 資料大時，計算可能耗時緩慢
 - 尺度量綱不一的屬性、名目屬性與遺缺數據需要額外處理

## 進階討論
1. 關於 k 近鄰 (k nearest neighbors) 學習 ，下列 敘述何者 「不」正確 A
- (A) 資料需服從常態分配
- (B) 因為沒有模型，所以限制了我們瞭解預測變數與目標變數之間關
係的能力
- (C) 度量綱不一的屬性、名目屬性與遺缺數據需要額外處理
- (D) k 近鄰法計算耗時，計算時須將數據載入記憶體中，當資料量大時通常用節省記憶體的資料結構，以加快計算，如 k 維樹 (k-dimensional tree, k-d tree)

2. 下列 何 種方法，訓練的速度通常最快？ A
- (A) k 近鄰法( k nearest neighbors)
- (B) 支援向量機 (supports vector machine)
- (C) 決策樹( decision tree)
- (D) 多層感知器( multilayer perceptron)

3. 關於 k 近鄰 法（ k nearest neighbors ），下列敘述何者正確？ B
- (A) 若 k =1 設得太低會導致 配適不足 underfitting
- (B) k 取較大的值，由較多的訓練樣本共同決定待測樣本的類別，比較穩定抗雜訊
- (C) 若 k =樣本數 每個待測樣本必須跟所有訓練樣本計算距離，計算量太大
- (D) k 取奇數 可以避免鄰近樣本在不同類別的數目相等，無法判定待測樣本類別

4. 下列何者不屬於非監督式學習？C
- (A) 局域離群因子（Local Outlier Factor）
- (B) 獨立成份分析（Independent Component Analysis）
- (C) 最近鄰法（Nearest Neighbor Methods）
- (D) 奇異值分解（Singular Value Decomposition）

5. 關於熱切式學習（Eager Learner）與偷懶式學習（Lazy Learner），下列敘述何者不正確？C
- (A) 熱切式學習是先利用訓練資料建立一個判別模型，以便進行測試
- (B) 決策樹屬於熱切式學習
- (C) 偷懶式學習會花很多時間在事先利用訓練資料建立判斷模型
- (D) k-最近鄰分類法（K-Nearest-Neighbor Classifiers）屬於偷懶式學習

6. 下列何種機器學習方法不屬於監督式學習演算法？ C
- (A) 邏輯迴歸（Logistic Regression）
- (B) 類神經網路（Neural Network）
- (C) 多維尺度法（Multidimensional Scaling）
- (D) 最近鄰居法（Nearest Neighbor）

7. 關於K近鄰法（K-Nearest Neighbor），下列敘述何者不正確？D
- (A) 根據現有已分類好的資料集合，找出K個與待分類資料最鄰近的現存資料
- (B) 根據K個最鄰近資料之類別，以多數決的方式決定待分類資料的所屬類別
- (C) 建議K為奇數值
- (D) 根據K值將資料分為K群

8. 下列何者不為監督式學習（Supervised Learning）方法？D
- (A) K近鄰法（K-Nearest Neighbor）
- (B) 支援向量機（Support Vector Machine）
- (C) 邏輯迴歸（Logistic Regression）
- (D) 自我組織映像圖（Self-OrganizingMap）

9. 在資料分析之前，需要花費很多力氣去整理資料，其中處理遺失值（Missing Value）便是一種，下列何者不是處理遺失值的手段？C
- (A) 移除有遺失值的資料
- (B) 使用平均數或第一四分位數來填補
- (C) 將前一筆資料的值填入
- (D) 使用K-近鄰法（K-Nearest Neighbours）搭配中位數進行填補
