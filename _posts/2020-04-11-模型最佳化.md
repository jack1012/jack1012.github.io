---
layout      : post
title          : 模型最佳化
date          : 2020-04-11 01:12:10 +0800
categories : 進階機器學習
tags           : [機器學習,模型參數最佳化]
---

# 模型最佳化
機器學習就是假設隨機誤差模型來希望從資料中將隱含且不精確的函數關係學習出來。

在機器學習中，最重要的就是要找到函數關係，也就是模型內部的參數，另外一個影響機器學習過的是在機器學習過程中學的參數，例如學習率、批量大小...等等，這是在模型之上的參數，被稱為超參數(hyper-parameters)。

目前許多機器學習的模型能夠建立非常複雜的模型，然而複雜的模型容易過度強調訓練樣本中未來不會重複出現的型態，因而產生過度配適(overfitted)的模型。因此，我們需要一套評估是否過度配適的指引方針，避免陷入過度配適的危機。

## 模型績效改進
下列方法可以避免機器學習模型過度配適（ Overfitting）
- 選擇特徵（ Feature Selection）
- 交叉驗證（ Cross Validation）
- 對目標函數施加懲罰（ Penalty）
- 增加資料量

### 模型參數調校
- 一般參數：模型上的參數
- 超參數：在訓練前就設定好，例如學習率
  - one-SE法則：一倍標準誤法則，依據全域最佳解下的預測誤差平均值與標準誤(一倍標準誤)之和，挑選預測誤差平均值不超過此門檻的最簡模型。

#### 練習題
A 11. 與隨機誤差建模相關的參數有模型參數和超參數（ hyperparameters），下列何者「 不是」 超參數？
(A) 迴歸方程式的截距
(B) 支援向量機中徑向基底核函數的 σ
(C) 人工神經網路的隱藏層節點數
(D) 建構迴歸方程式的預測變數集

C 197. 梯度遞減法（ Gradient Descent）是機器學習中常使用的參數收斂方式，我們可以透過參數 alpha 來調整整體收斂的速度（ Step Size），請問如果 alpha 過大時，會導致什麼狀況發生？
(A) 太快收斂
(B) 收斂速度過慢
(C) 無法收斂
(D) 以上皆有可能發生

### 比較不同類模型
