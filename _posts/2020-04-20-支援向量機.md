---
layout      : post
title       :  支援向量機
date        : 2020-04-20 10:41:10 +0800
categories  : 進階機器學習
tags        : [機器學習,分類模型,支援向量機]
---

# 支援向量機(Support Vector Machines, SVM)
支援向量機是分類、異常偵測與迴歸的優秀工具。其分類模型起源於最大邊界分類器(maximal margin classifiers)，藉由最大化分類超平面與資料之間的邊界幅度，決定出分割不同類樣本的最佳決策邊界。

## 原始問題：最大邊界分類器(maximal margin classifiers)
假設訓練集合 $S= \{(x_i, y_i) | x_i \in \mathbb{R} ^{m},y_i \in \{+1,-1\} \}$ ，個數 $n$ 。
- $x_i$是訓練樣本，$m$個維度，在平面中表示就是$2$維。
- $y_i$是 $-1$ 或者 $+1$，也就是分類結果，"$-1$"這類或"$+1$"那類，這個 $y$ 不是下圖的座標軸 $y$ 喔。

找出一個超平面(hyperplane)，使之將兩個不同的集合分開。以二維平面來說，我們希望能找出一條線能夠將兩種不同的點分開，而且我們還希望這條線距離這兩個集合的邊界越大越好。

![1](svm.png)

不失一般性假設此超平面的係數為 $[b, \mathbf{w}^T ]= [w_0, w_1, \cdots, w_m ]$

- $\mathbf{w}\cdot\mathbf{x} + b=0$：分離超平面(separating hyperplane)
- $\mathbf{w}\cdot\mathbf{x} + b=1$：支持超平面(support hyperplane)
- $\mathbf{w}\cdot\mathbf{x} + b=-1$：支持超平面(support hyperplane)

找出最佳分離超平面的問題就等於找出相距最遠的支持超平面，兩支持超平面最遠距離 $\text{margin}(\mathbf{w}) =  \frac{2}{||\mathbf{w}||}$(利用平面距離公式)

同時為了使得樣本數據點都在超平面的間隔區以外，我們需要保證對於所有的 $i$ 滿足其中的一個條件

$$\forall i ,
\mathbf{w}\cdot\mathbf{x_i} - b \ge 1
\qquad\mathrm{or} \qquad
\mathbf{w}\cdot\mathbf{x_i} - b \le -1   $$

這兩個式子可以寫成一個：
$$y_i(\mathbf{w}\cdot\mathbf{x_i} - b) \ge 1, \quad 1 \le i \le n.\qquad\qquad (1)$$

現在尋找最佳超平面這個問題就變成了在 $(1)$ 這個約束條件下最小化 $||\mathbf{w}||$。

最小化 $||\mathbf{w}||$ 等同於最小化 $||\mathbf{w}||^{2}$ ，所以可以更清楚的表示：

$\operatorname*{argmin}\limits_{\mathbf{w},b}{||\mathbf{w}||^2\over2}$，滿足$y_i(\mathbf{w}\cdot\mathbf{x_i} - b) \ge 1$其中 $i = 1, \dots, n$。

這是一個二次規劃QP (quadratic programming)最優化中的問題。

## 進階討論
1. 下列何種方法，最適合解決非線性分類問題及高維空間數據識別問題？ A
- (A) 支援向量機（Support Vector Machine）
- (B) K平均法（K-means）
- (C\) 貝式判別（Bayesian Classifier）
- (D) 模糊理論（Fuzzy Set）

2. SVM的特點：
- 背後的最佳化問題為凸性的(convex)，因此只有一個最佳解存在
- 可用於分類問題或迴歸問題，且績效通常十分卓越
- 核函數攸關資料的映射，也就是說和函數的統計機器學習方法是分析先前資料應的建模方法，資料內隱含地映射到一個高維的屬性空間，然後嘗試運用比較簡單的線性分類模型解決低維度下困難的問題
- 學習發生在轉換後的屬性空間中，但我們僅需以原始資料的內積來表達運算，因此避免掉計算高維度空間的繁複運算過程，這種技巧被稱為和函數謀略
- 不容易受雜訊資料過度影響，也較不易過度配適
- 屬於灰盒模型，結果不易詮釋

3. 進階參考資料 [https://www.itread01.com/content/1544583806.html]

4. 不足之處：
(1) SVM演算法對大規模訓練樣本難以實施
(2) 用SVM解決多分類問題存在困難
(3)對缺失資料敏感，對引數和核函式的選擇敏感

5. 支援向量機的主要應用和研究的熱點
- 目前支援向量機主要應用在模式識別領域中的文字識別、中文分類、人臉識別等；同時也應用到許多的工程技術和資訊過濾等方面。
- 當前研究的熱點主要是對支援向量機中演算法的優化，包括解決SVM中二次規劃求解問題、對大規模SVM的求解問題、對SVM中QP問題的求解問題...等。
- 另外就是如何更好的構造基於SVM的多類分類器、如何提高SVM的歸納能力和分類速度...等；
- 如何根據實際問題確定核函式也是一個重要的研究熱點.

#### 練習題
B 1. 關於支援向量機（ Support Vector Machine, SVM）的模型超參數（ hyperparameters）， 下列敘述何者「不」正確？
(A) 懲罰係數 C 越高，越容易過度最佳化
(B) 支援向量的數目要事先決定
(C) 核函數（ kernel function） 要事先決定
(D) 網格搜尋（ Grid Search） 常用來尋找超參數（ hyperparameters）
