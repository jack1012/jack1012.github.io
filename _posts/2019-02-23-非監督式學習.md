---
layout      : post
title       : 非監督式學習
date        : 2019-02-23 10:41:10 +0800
categories  : 資料處理與分析概論
tags        : [資料分析,機器學習概論,非監督式學習]
---
# 2-3 非監督式學習

- 關聯規則學習（Association rule learning）
- K 平均法（ K-Means）
- 主成分分析（ Principle Component Analysis）
- Hierarchical-Clustering
- Auto-Encoder
- Word2Vec

#### 練習題
138 機器學習的方式
B 138. 關於機器學習的方式，下列敘述何者正確？
(A) 非監督式學習的目標通常清晰
(B) 一般而言我們很難評估非監督式學習結果的好壞
(C) 監督式學習通常是探索式資料分析的一部分
(D) 非監督式學習的目標就是預測反應變數

139 非監督式學習
A 139. 下列何者不是非監督式學習的任務？
(A) 上傳至社群網路的相片是否有人臉
(B) 在癌症樣本中，或是基因變數中尋找可能的子群，以對此疾病有更好的瞭解
(C) 線上購物網站嘗試依相似的瀏覽習慣與採購記錄將消費者分群，並將同群消費者購買的品項集合在一起
(D) 搜尋引擎也會依據具有相同搜尋型態的使用者點擊歷程，決定呈現哪些搜尋結果


31非監督式學習
C 31. 下列何者為「非監督式學習」演算法？
(A) 決策樹（ Decision tree）
(B) 集成方法（ Ensemble Methods）
(C) K 平均法（ K-Means）
(D) 支援向量機（ Support Vector Machine）

32非監督式學習
B 32. 關於非監督式學習，下列敘述何者正確？
(A) 意指不需要人看著就能學習
(B) 常見的集群分析屬於非監督式學習
(C) 常見的分類模型屬於非監督式學習
(D) 以上皆非

40非監督式學習
C 40. 下列何者不屬於非監督式學習？
(A) 局域離群因子（ Local Outlier Factor）
(B) 獨立成份分析（ Independent Component Analysis）
(C) 最近鄰法（ Nearest Neighbor Methods）
(D) 奇異值分解（ Singular Value Decomposition）

83非監督式學習
C 83. 下列哪一項技術屬於非監督式學習？
(A) 決策樹（ Decision Tree）
(B) 類神經網路（ Neural Network）
(C) 集群分析（ Clustering Analysis）
(D) 支援向量機（ Support Vector Machine）

90非監督式學習 PCA
D 90. 在非監督式學習方法中， 下列何者最常被做為資料降維的方法使用？
(A) K 平均法（ K-means）
(B) 最大期望算法（ Expectation-maximization）
(C) 模糊 C 平均法（ Fuzzy C-means）
(D) 主成分分析（ Principle Component Analysis）

131 非監督式學習
D 131. 關於「非監督式學習」（ Unsupervised Learning），下列敘述何者正確？
(A) 輸出屬性值是可以被預測的
(B) 需用測試集測試所建立模型的正確性
(C) 輸入資料的形式只能是類別資料型態
(D) 建立模式用的資料，並不是事前定義好的

48非監督式學習
A 48. 下列何者為非監督式學習（ unsupervised learning） 演算法？
(A) 關聯規則學習（ association rule learning）
(B) 決策樹（ decision tree）
(C) 天真貝氏法（ Naïve Bayes）
(D) 隨機森林（ random forest）

7非監督式學習
D 7. 下列何者「不屬於」 非監督式學習？
(A) 關聯法則
(B) K-Means
(C) Word2Vec
(D) K Nearest Neighbor

40非監督式學習
A 40. 關於非監督式學習（ unsupervised learning），下列敘述何者「不正確」 ？
(A) 線性可加模型（ General Additive Models, GAM）、效能提升模型（ Boosting） 與支援向量機（ Support Vector Machine, SVM） 等屬於非監督式學習的範疇
(B) 研究是否預測變數（ predictors） X1, X2, . . . , Xp 之間存在有趣的型態
(C) 研究是否能以具訊息力的方式視覺化資料背後的結構與關係
(D) 能發現變數間或觀測值間的子群體

189 非監督式學習
D 189. 關於非監督式學習，下列敘述何者正確？
(A) 以預測變數（ predictors）來準確預測反應變數（ response variable）
(B) 瞭解反應變數與預測變數兩者間的關係
(C) 線性迴歸與羅吉斯迴歸都屬於非監督式學習
(D) 能發現變數間或觀測值間的子群體

240 非監督式學習
D 240. 下列何者不屬於非監督式學習的演算法？
(A) PCA
(B) Hierarchical-Clustering
(C) Auto-Encoder
(D) XGBoost


## 頻繁型態分析(關聯型態探勘)

#### 練習題
32關聯型態探勘的特點
A 32. 關於關聯型態探勘的特點，下列敘述何者「不正確」 ？
(A) 關聯型態探勘所得到的結果，因為可以直接進行應用，所以廣受歡迎
(B) 關聯型態分析容易從隨機的型態中妄下虛假的結論
(C) 關聯型態探勘符合資料探勘挖掘資料庫中無預期知識的理念
(D) 關聯型態探勘的分析方法對於小資料集的用處不大


140 關聯規則分析
D 140. 關於關聯規則分析（ Association Rule），下列敘述何者不正確？
(A) 典型的關聯規則分析， 是分析超市中顧客購買的品項集合資料（通常被稱為交易資料，或是購物籃資料），其個別品項間或品項群間的關聯
(B) 關聯規則分析最常見的模型，是以品項集合出現的次數，來量化彼此間的關聯程度，以此探勘出來的品項集合稱為頻繁品項集（ Large Itemsets or Frequent Itemsets）
(C) 關聯規則分析的目的，是基於某些品項出現的前提下，挖掘出可預測其它品項發生之可能性的規則，這些規則就被稱為關聯規則
(D) 關聯規則分析在資料探勘領域中，不容易與其它方法論結合運用，例如：集群、分類與離群值分析等

36關聯型態探勘
C 36. 關於關聯型態探勘（ Association Pattern Mining），下列敘述何者「不正確」？
(A) 典型的關聯型態探勘是分析超市中顧客購買的品項集合資料（ 通常被稱為交易資料，或是購物籃資料），其個別品項間或品項群間的關聯
(B) 關聯型態挖掘最常見的模型是以品項集合出現的次數，來量化彼此間的關聯程度，以此挖掘出來的品項集合稱為頻繁品項集（ Large Itemsets or Frequent Itemsets）
(C) 就應用領域而言，關聯型態探勘僅應用於購物籃資料分析，因而被稱為購物籃分析（ Market Basket Analysis）
(D) 關聯型態探勘分析的目的是基於某些品項出現的前提下，挖掘出可預測其它品項發生之可能性的規則，這些規則就被稱為關聯規則

36關聯規則
D 36. 關於「 關聯規則（ association rule）」，下列敘述何者「不正確」 ？
(A) 關聯規則可以從商品交易中找出隱含的購買規則
(B) 支持度（ support）是衡量前提項目（ antecedent item）與結果項目（ consequent item）一起出現的機率
(C) 信賴度（ confidence）是衡量前提項目發生情況下，結果項目發生的條件機率
(D) 增益率（ lift）是衡量信賴度與前提項目單獨發生時二者機率比值

190 關聯型態探勘
A 190. 關於關聯型態探勘的特點，下列敘述何者不正確？
(A) 關聯型態探勘所得到的結果，因為可以直接進行應用，所以廣受歡迎
(B) 關聯型態分析容易從隨機的型態中妄下虛假的結論
(C) 關聯型態探勘符合資料探勘挖掘資料庫中無預期知識的理念
(D) 關聯型態探勘的分析方法對於小資料集的用處不大


93關係分析
B 93. 根據下表，我們要預測該公司的顧客是否會買電腦，若規則 R:(年齡=青年)Λ (學生=是)=>(購買電腦=是)，則規則 R 的覆蓋率與正確率分別為何？
某公司顧客資料庫的訓練資料
No. 年齡 收入 學生 購買電腦
1 青年 高 否 否
2 青年 高 否 否
3 中年 高 否 是
4 老年 中 否 是
5 老年 低 是 是
6 老年 低 是 否
7 中年 低 是 是
8 青年 中 否 否
9 青年 低 是 是
10 老年 中 是 是
11 青年 中 是 是
12 中年 中 否 是
13 中年 高 是 是
14 老年 中 否 否
(A) 覆蓋率為 14.28% 與正確率為 92.86%
(B) 覆蓋率為 14.28% 與正確率為 100%
(C) 覆蓋率為 28.57% 與正確率為 92.86%
(D) 覆蓋率為 28.57% 與正確率為 100%

96 Apriori演算法
B 96. 關於 Apriori 演算法，下列敘述何者不正確？
(A) 使用於關聯規則分析
(B) 屬於協同過濾推薦的一環
(C) 需要產生大量候選項集和需要重複掃描資料庫
(D) 支持度大於最小支持度的項集稱為頻繁項目集

D 17. 此例交易資料用 Apriori 演算法尋找頻繁項目集（ frequent itemsets），最小支持度（ minimum support） 要設多少，才會有長度為 3 的頻繁項目集？
(A) 0.3
(B) 0.27
(C) 0.25
(D) 0.22

B 22. 關於關聯分析： FP-growth 演算法（ Frequent Pattern-growth），下列敘述何者「 不」 正確？
(A) 這是一種沒有生成候選項目集的頻繁項目集探勘方法
(B) 採用類似 Apriori 方法的生成和測試（ generate-and-test）策略
(C) 它構造了一個高度緊湊的資料結構（ FP-tree）來壓縮原始交易資料庫
(D) 它著重於頻繁項目的增長，避免昂貴的候選生成

## 集群分析

#### 練習題
34分群演算法
A 34. 下列何種分群演算法， 是基於「密度」概念所設計的？
(A) OPTICS 演 算 法 （ Ordering Points To Identify the Clustering Structure）
(B) K 平均法（ K-means）
(C) 聚合式階層分群法（ Agglomerative Hierarchical Clustering）
(D) 社群偵測（ Community Detection）


33Kmeans
B 33. 關於 K 平均法（ K-means）的分群，下列敘述何者不正確？
(A) 一開始群的中心點可以是隨機選擇的
(B) 每次分群的結果都一模一樣
(C) 每次分群結果必須讓組內平方和最小
(D) 一開始必須告知該演算法欲分群的群數

81Kmeans
D 81. 關於 K 平均法（ K-means），下列敘述何者不正確？
(A) 希望找出 k 個互不交集的群集
(B) 不同的起始群集中心，可能會造成不同的分群結果
(C) 容易受雜訊與離群值影響其群集中心
(D) 可以處理類別型資料


85集群分析
D 85. 關於集群分析（ Clustering Analysis），下列敘述何者不正確？
(A) 依照相似度將資料分群
(B) 同一群內的相似度大
(C) 各群之間的相似度小
(D) K-means 每次分群結果一定會相同

86階層式集群分析
C 86. 關於階層式集群分析（ Hierarchical Clustering），下列敘述何者不正確？
(A) 一般採用樹狀圖（ Dendrogram）表示
(B) 樹狀圖根節點（ Root）為單一群集
(C) 聚合法（ Agglomerative）是由上方根節點往下進行計算
(D) 分裂法（ Divisive）是一開始將所有資料視為一個大群集

87階層式集群分析
C 87. 關於階層式集群分析（ Hierarchical Clustering）的方法，下列敘述何者不正確？
(A) 單一連結法（ Single Linkage Method）採用兩群間最小距離
(B) 完全連結法（ Complete Linkage Method）採用兩群間最大距離
(C) 平均連結法（ Average Linkage Method）採用兩群間中心點距離
(D) 華德法（ Ward's Method）是計算組內變異作為評估群集相似性

89資料分群
A 89. 下列何種統計學習的演算法是用來進行資料的分群（ Clustering），但不能用來進行資料分類（ Classification）？
(A) 基於密度的集群分析算法（ Density-Based Spatial Clustering of
Applications with Noise， DBSCAN）
(B) 貝氏網路（ Bayisian Network）
(C) 隨機森林（ Random Forest）
(D) 支援向量機（ Support Vector Machine）

133 K-means
C 133. 關於 K-means 演算法，下列敘述何者不正確？
(A) 將 n 筆待分群的資料選出 k 個資料點為集群的中心點
(B) 將所有資料與此 k 個中心點做距離運算
(C) 穩定性高，對異常值或極值不敏感
(D) 每次計算 K-means，分群結果不一定相同


134 階層分群
D 134. 關於階層式分群，下列敘述何者不正確？
(A) 階層式分群法可以用樹狀結構呈現計算過程
(B) 使用階層式分群法時，必須定義資料群之間的距離計算方式
(C) 階層式分群可應用於小資料集
(D) 階層式分群法需一開始給定群的數目

181 DBSCAN基於密度的集群分析法
C 181. 關於「 基於密度的集群分析算法（ Density-Based Spatial Clustering of Applications with Noise， DBSCAN）」下列敘述何者不正確？
(A) 是以中心點為基礎的方法
(B) 能抵抗雜訊，且能處理任何形狀和大小的群集
(C) 需要人工指定集群的數目
(D) 找出遠離低密度區域之高密度的區域

182 階層式群集
C 182. 下列關於階層式集群，何者不正確？
(A) 概念簡單，可用樹狀結構來表現整個計算過程
(B) 只需要資料點兩兩之間的距離，就可以建構集群結果
(C) 即使處理大量資料也能保持高效率
(D) 不需要事先定義群數

184 K-means
B 185. 關於 K 平均法（ K-Means），下列敘述何者不正確？
(A) 將資料分割成不相交的 K 個群集
(B) 如果資料與某群集中心的相似度大於其他群集，則該資料歸類於其他群集
(C) 目標是達到群集內的距離平方達到最小
(D) 目標是達到群集間的距離平方達到最大

186 K-means
C 186. 下列何種問題適合使用 K 平均法（ K-Means）？
(A) 家庭背景對薪資的影響
(B) 男性的長相對其女朋友數量的影響
(C) 根據花蕊長和花瓣寬將花朵集群
(D) 根據上下文填入克漏字

187 K-means
C 187. 關於 K 平均法（ K-Means）集群分析，下列敘述何者不正確？
(A) 事前需要估算資料中有多少集群存在，方能執行演算法
(B) 不適合非球形或數據密度變化大的集群問題
(C) 算法只要收斂，保證可以獲得最佳的集群結果
(D) 算法可彈性變化，經過簡單的調整後，可以解決大部份的缺點

33集群問題
D 33. 下列何種方法通常應用在集群（ clustering）問題？
(A) 支援向量機（ support vector machine）
(B) 隨機森林（ random forest）
(C) k 近鄰法（ k nearest neighbors）
(D) k 平均數（ k-means）

34Kmeans
C 34. 關於 k 平均數（ k-means） 與噪訊偵測之空間密度集群算法（ Density-Based Spatial Clustering of Applications with Noise, DBSCAN），下列敘述何者「不正確」 ？
(A) 兩者都是集群分析
(B) k-means 基於距離的概念，而 DBSCAN 基於密度的概念
(C) 兩者都需要事先告知分群的數量
(D) k-means 集群結果易受離群值的影響

35階層式集群法
C 35. 關於傳統「階層式集群法（ hierarchical cluster analysis）」，下列敘述何者「不正確」 ？
(A) 常 利 用 聚 合 法 （ agglomerative approach ）和分裂法 （ divisive approach）產生所需的階層結構
(B) 將彼此相似度高的較小群集合併成較大的群集，或者將較大群集進行分離
(C) 利用資料點間密度的關係來分群
(D) 利用樹狀結構圖表示群集彼此關係之分群法

37 Kmeans
D 37. 關於 k 平均數（ k-means） 集群分析， 下列敘述何者正確？
(A) 適合解決非球形或數據密度變化大的集群問題
(B) 演算法算法只要收斂，保證可以獲得最佳的集群結果
(C) 事前不需要估算資料中有多少集群存在，即能執行算法
(D) 不如其它集群演算法精細縝密，但在許多真實的情境下，能將集群的任務處理得足夠好

231 集群分析
D 231. 下列何種方法通常應用在集群（ Clustering） 問題？
(A) Support Vector Machine
(B) Random Forest
(C) K Nearest Neighbors
(D) K-Means


235 K-means
B D235. 關於 K-means 集群演算法， 下列敘述何者正確？
(A) 當集群中心不再變動，就達到全局最佳解（ global optimum）
(B) 必須事先給定群組數目 K 值
(C) 集群結果只與資料群聚分佈方式有關
(D) 對異常值、極值的資料敏感

238 階層式群集
D 238. 關於階層式分群法（ Hierarchical Clustering），下列敘述何者不正確？
(A) 若採用聚合的方式， 則由樹狀結構的底部開始，將資料或群集逐次合併
(B) 若採用分裂的方式，則由樹狀結構的頂端開始，將群集逐次分裂
(C) 群與群的距離定義為不同群聚中最近的兩個點的距離，該法稱為單一聯結法（ Single Linkage，又稱「最近法」）
(D) 事先必須告知分群數量，以利分群法之進行

239 K-Means 與 DBSCAN
C 239. 關於 K-Means 與 DBSCAN，下列敘述何者不正確？
(A) 兩者都是集群分析
(B) K-Means 基於距離的概念，而 DBSCAN 基於密度的概念
(C) 兩者都需要事先告知分群的數量
(D) K-Means 集群結果易受離群值的影響

D 18. 集群（ clustering）是以非監督（ unsupervised）方式定義其欲解決的問題，所以只能透過一些常用的內部核驗準則來評估結果，下列何者「不是」 內部核驗準則？
(A) 各群樣本點到中心距離的平方和
(B) 群內距離相對於群間距離的比值
(C) 側影係數（ silhouette coefficient）
(D) 類別標籤

A 19. 下列何種集群法（ clustering）是利用兩兩樣本（或群）間的距離與樹狀結構，將資料進行分群，一開始會將所有的資料視為一個完整的群體，在迭代過程中不斷的分裂為較小的群體，直到所有的資料都成為單獨的個體？
(A) 階層式集群
(B) 密度集群
(C) k-means 集群
(D) k-medoids 集群

B 20. 下列何者是 k 平均數集群（ k-means clustering）的優點？
(A) 算法涉及隨機抽樣，每次運行的結果不盡相同
(B) 原理簡單，容易以非統計的詞彙解釋說明之
(C) 形成的群多為類圓球狀且大小相近
(D) 不易受到離群值的影響


## 離群值分析

#### 練習題
D 24. 以密度為基礎的離群值偵測方法，下圖中有哪些點最可能是離群值（ Outlier） ？
(A) O4
(B) O1, O2
(C) O3
(D) O1, O2, O3

B 26. 關於離群值檢測（ outlier detection）可能面臨的挑戰，下列敘述何者「不」正確？
(A) 異常值檢測高度依賴於正常（ 非異常值） 和異常值的有效建模
(B) 一般檢測方法與應用無關（ application-independent）
(C) 異常值與雜訊不同
(D) 檢測到異常值具備易理解性（ understandability）
