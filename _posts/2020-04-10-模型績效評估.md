---
layout      : post
title       : 模型績效評估
date        : 2020-04-10 10:41:10 +0800
categories  : 進階機器學習
tags        : [機器學習,模型績效評估]
---

# 模型績效評估

## 模型的配適

模型的配適主要從機器學習中的資料來探索，機器學習過程中將資料切分成訓練子集(training set)和測試子集(testing set)，訓練子集用來建立模型，測試子集用於評估模型績效表現。下圖是兩個資料子集下模型複雜度與預測誤差之間的關係圖。

![模型複雜度與預測誤差之間的關係圖](20112540fLYimc78gu.png)

高度複雜的模型幾乎可以分毫無差地配適任何資料，也就是真實的 $y$ 與預測的 $\hat y$ 之間的偏差(殘差)幾乎是零。但這樣的模型對於未用於建模的測試樣本不一定管用，產過度配適的狀況。這種現象說明訓練資料配適過度的模型不一定有足夠的一般化的能力。

從理論上來分析，基本上資料內涵的訊息可以分成兩個部分：有興趣的型態(pattern)與隨機雜訊(stochastic noise)。舉例來說，房價取決於房屋面積與臥房間數，越多的臥室通常房價愈高。但是同區的房產且臥室相同的房子，不太可能會有完全相同的房價，所以這些房價的變動就適雜訊。

機器學習的目標適建立有興趣型態的模型，而盡量減少雜訊的干擾影響。因此當算法試圖配適除了型態以外的雜訊，所產生的模型就會適過度配適。而因為雜訊是隨機的，所以過度配適的模型無法一般化到未知的資料。

### 模型的配適有四種狀況
- 配適不足：測試誤差高，訓練誤差高
- 過度配適：測試誤差高，訓練誤差低
- 配適良好：測試誤差低，訓練誤差低
- 配適不明：測試誤差低，訓練誤差高

機器學習的目標是要將模型參數調整至配適良好的情況。因此資料分析與建模的工作經常是嘗試錯誤(trial-and-error)的過程，而失敗的次數通常高於成功的喜悅，及早累積資料處理與分析的實戰經驗是成為頂尖資料科學家的不二法門。

PS：上圖中沒有顯示出配適不明的狀況，很少有這樣的狀況，如果有遇到再補充上來。 配適不明可能是訓練即有許多難搞的樣本，而測試集大多是容易預測的樣本。

#### 練習題
B 14. 當資料科學家建模時，如果有測試誤差高，訓練誤差低的狀況時，稱為下列何者？
(A) 配適不足
(B) 過度配適
(C) 配適良好
(D) 配適狀況不明

244 配適不足
C 244. 關於配適不足（ under-fitting），下列何者正確？
(A) 訓練誤差較大，測試誤差較小
(B) 訓練誤差較小，測試誤差較大
(C) 訓練誤差較大，測試誤差較大
(D) 訓練誤差較小，測試誤差較小


47Overfitting
D 47. 下列哪種方法可以避免機器學習模型過度配適（ Overfitting）？
(A) 選擇特徵（ Feature Selection）
(B) 交叉驗證（ Cross Validation）
(C) 對目標函數施加懲罰（ Penalty）
(D) 以上皆是


145 過度擬合
A 145. 下列何者為「學習模型時，為了得到好的準確度」而容易造成的問題？
(A) 過度擬合（ Overfitting）
(B) 資料標籤不均（ Imbalanced Data）
(C) 資料維度過高
(D) 資料集過大

41模型評估
C 41. 模型複雜度與預測誤差之間的變化關係，通常是越複雜的模型與訓練集合配適的越好。因此，一般而言訓練集的預測誤差，會隨著模型複雜度如何變化？
(A) 增加而增加
(B) 減少而減少
(C) 增加而減少
(D) 減少而增加

45過度擬合
A 45. 在進行機器學習時，下列何者「不是」避免過度配適（ overfitting） 的方法？
(A) 減少資料量
(B) 減少模型參數
(C) 使用較簡單的模型
(D) 在損失函數（ loss function） 加入參數權重的 L2 norm，抑制權重變大


## 迴歸模型績效指標
- 誤差平方和(SSE)：殘差平方的總和
- 誤差絕對值和(SAE) ：是預期值與實際值之間的相對絕對差值；相對是因為會將平均值差除以算術平均值。
- 平均絕對誤差 (MAE)： 會測量預測與實際結果的接近程度；因此，分數越低越好。
- 誤差的標準差(SEP)
- 均方預測誤差(MSE)
- 均方根預測誤差(RMSE)： 會建立單一值來彙總模型中的錯誤。 藉由將差值平方，此計量可忽略預測過頭和預測不足之間的差異。
- 相對平方誤差 (RSE) ：同樣會將預測值的總平方誤差除以實際值的總平方誤差來將預測值的總平方誤差正規化。
- 判定係數(R^2)：可用 0 與 1 之間的值來表示模型的預測能力。 0 表示模型是隨機的 (無法說明任何事)；1 表示有完美的配適。 不過，請小心解讀 R2 值，因為較低的值可能是完全正常，較高的值則很可疑。
- 赤池宏次訊息準則(AIC)
- 舒瓦茲貝式訊息準則(BIC)

#### 練習題
45判定係數
B 45. 如果判定係數為 0.8，則依變數能被自變數解釋的變異百分比為？
(A) 0.8%
(B) 80%
(C) 0.64%
(D) 不一定

95Overfitting
C 95. 關於過度配適（ Overfitting），下列敘述何者不正確？
(A) 知識發掘的方法在建立模型的過程中容易出現過度配適的情形，模型可能陷入只能解釋在訓練集樣本的關聯，而沒辦法一體適用
(B) 機器學習所學到的假設（ Hypothesis）過度貼近訓練資料（ Training Data），而導致測試資料（ Testing Data）錯誤率變得更大
(C) 過度配適表示測試資料的正確率極高
(D) 為了避免過度配適現象，必須使用額外的技巧，如交叉驗證、 EarlyStopping、貝斯信息量準則（ BIC）、赤池信息量準則（ AIC）等

149 線性迴歸模型評估
B 149. 關於線性迴歸模型績效評估，下列敘述何者不正確？
(A) 評估模型績效的方式不只一種
(B) 通常可透過混淆矩陣評估模型績效
(C) 殘差繪圖（ Residual Plots）是以視覺化的方式檢視模型的配適狀況
(D) 許多績效評量的計算是基於殘差（ Residual），它是各觀測值減去其模型的預測值，而常用的 SSE 是殘差平方的總和

174 迴歸分析(判定係數)
D 174. 請參考以下迴歸分析結果：
下列敘述何者正確？
(A) 模型不具有線性模型解釋能力
(B) 模型的截距為 3.45000
(C) 模型的樣本數為 13
(D) 模型的判定係數（ Coefficient of Determination）為 0.991

199 模型績效評估
D 199. 關於迴歸模型績效評估，下列敘述何者正確？
(A) 評估模型績效的方式不只一種，通常只用一種模型績效評估的方式來決定模型的優劣
(B) 許多績效評量的計算是基於殘差（ residual），它是模型的預測值減去觀測值
(C) 常用的績效評量 SSE 是殘差平方的平均值，而另一個常用的績效評量 MSE 是殘差平方的總和
(D) R2 也是常用的績效評量，其值表示資料中的訊息被模型所解釋的比例， R2 的解釋與結果變數的變異有關

46AIC BIC模型判定
A 46. 下方表格是針對同一份資料建立的四種複迴歸模型， 根據各種模型之
指標資訊， 請問下列何者為最佳模型？
模型編號 模型 AIC BIC Cp R2
模型 1 -55 50 3 0.8
模型 2 -55 50 4 0.8
模型 3 -30 60 3 0.8
模型 4 10 100 3 0.8
AIC 為赤池信息量準則（ Akaike Information Criterion）；
BIC 為貝葉斯信息準則（ Bayesian Information Criterion）；
Cp 為馬洛斯 Cp（ Mallows’Cp）；
R2 為判定係數（ coefficient of determination）
(A) 模型 1
(B) 模型 2
(C) 模型 3
(D) 模型 4

B 12. 真實的反應變數值與預測的反應變數值之間的差，稱為殘差或（預測）誤差，下列何者是應用殘差平方值的算術平均來評估迴歸模型的績效？
(A) 誤差平方和（ Sum of the Squared Errors, SSE）
(B) 均方預測誤差（ Mean Squared Error , MSE）
(C) 均方根預測誤差（ Root Mean Squared Error, RMSE）
(D) 誤差絕對值和（ Sum of Absolute Error, SAE）

## 分類模型績效指標
- 混淆矩陣
- 正確率、錯誤率：會測量分類模型的健全情況，表現方式為 True 結果對整體案例的比例。
- kappa統計量：用於檢驗兩次以上觀測的一致性程度，Kappa值的理論取值在0-1範圍內，Kappa值為0-0.4時認為是不理想，值大於0.75則認為具有及較好的一致性。
- 召回率( Recall)：是 True 結果對所有正面結果的比例。 Precision = TP/（TP + FP）
- 精準度(Percision)：是實際抓取的相關實例總數的分數。 召回 = TP/（TP + FN）
- F-measure：F1 分數：會計算為精確度的加權平均值，並在0和1之間重新叫用，其中理想的 F1 分數值是1。
- ROC曲線：以假陽性率（ False Positive Rate, FPR） 為 X 軸，以真陽性率（ True Positive Rate, TPR） 為 Y 軸
- AUC：會測量透過 y 軸上的正判和 x 軸上的誤判繪製出的曲線下的區域。 此計量十分有用，因為其會提供單一數字來讓您比較不同類型的模型。


#### 練習題
46Confusion Matrix
C 46. 假設在一混淆矩陣（ Confusion Matrix）中，真陽性（ True positive）為100，假陽性（ False Positive）為 50，真陰性（ True Negative）為 50，假陰性（ False Negative）為 800，請問該混淆矩陣的準確度（ Accuracy）為？
(A) 0.6667
(B) 0.9412
(C) 0.15
(D) 0.84

97Confusion Matrix
C 97. 假設在一混淆矩陣（ Confusion Matrix）中，真陽性（ True Positive）為 100，假陽性（ False Positive）為 50，真陰性（ True Negative）為 50，假陰性（ False Negative）為 800，請問該混淆矩陣的真陽性率（ True Positive Rate）為？
(A) 0.15
(B) 0.9
(C) 0.6667
(D) 0.1

50混淆矩陣
D 50. 關於二元分類（ binary classification），若一分類模型產生之混淆矩陣（ confusion matrix） 如下，該模型之精確度（ precision） 為下列何者？
|---------|-True-|- False-|
 |True |8 |3|
 |False |12| 11|
(A) 3/11
(B) 8/20
(C) 19/34
(D) 8/11

38混淆矩陣
C 38. 對於二元分類問題，依真實資料的真假值與模型預測輸出的真假值，可以組合出真陽性（ True Positive, TP）、真陰性（ True Negative, TN）、偽陽性（ False Positive, FP）、偽陰性（ False Negative, FN） 四種情況，組成混淆矩陣（ Confusion matrix）。若模型追求較高的精確率（ precision），則應提高下列何者？
(A) TP
(B) TN
(C) TP/(TP+FP)
(D) TP/(TP+FN)

C 16. 有一個混淆矩陣（ confusion matrix），橫列表示預測類別，縱行表示真實類別，假設有一個預測類別矩陣為[0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1 ,1]，真實類別矩陣為[1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0 ,1]， 則假陽數（ false positive）的值為何？
(A) 3
(B) 5
(C) 2
(D) 6



44ROC
C 44. 關於下方接收者操作特性曲線（ Receiver Operating Characteristic Curve,ROC） 圖，下列敘述何者正確？
(A) 假陽率（ false positive rate）數值愈大表示分類較準確
(B) 真陽率（ true positive rate）數值愈大表示分類較不準確
(C) 支援向量機（ Support Vector Machine, SVM） 模型分類準確率較類神經網路（ Neural Network, NN） 模型為佳
(D) 上述接收者操作特性曲線無法判斷支援向量機（ Support Vector Machine, SVM） 模型或類神經網路（ Neural Network, NN） 模型的分類準確率


B 10. 關於接收者操作特性曲線（ Receiver Operating characteristic Curve, ROC），下列敘述何者「 不」 正確？
(A) ROC 曲線往左上角移動，代表模型的敏感度越高
(B) AUC=0.8，代表無鑑別力
(C) ROC 常用於分析二元分類模型
(D) ROC 曲線是以假陽性率（ False Positive Rate, FPR） 為 X 軸，以真陽性率（ True Positive Rate, TPR） 為 Y 軸

D 9. 下列何者「 不是」 用來評估模型的驗證指標（ validation index） ？
(A) 均方誤差（ Mean Squared Error, MSE）
(B) 混淆矩陣（ confusion matrix） 與敏感度（ sensitivity）
(C) ROC 曲線與曲線下方面積（ Area Under Curve, AUC）
(D) 特徵值（ eigenvalue）

## 群集模型指標
針對群集模型傳回的統計資料會描述指派給每個叢集的資料點數目、叢集之間的分隔量，以及每個叢集內資料點的緊密程度。

群集模型的統計資料會取整個資料集的平均值，並會有額外的資料列包含每一叢集的統計資料。

系統會報告下列計量以供評估群集模型：
- 與其他中心的平均距離：資料行中的分數，表示叢集中的每個點與所有其他叢集的距心接近程度平均值。
- 與叢集中心的平均距離：資料行中的分數，表示叢集中的每個點到該叢集距心的接近程度。
- 點數：資料行會顯示指派給每個叢集的資料點數量，以及任何叢集中的資料點整體總數。
  - 如果指派給叢集的資料點數目小於可用的資料點總數，則表示無法將資料點指派給叢集。
- 與叢集中心的最大距離：資料行中的分數代表每個點和該點的叢集距心之間的距離上限。
  - 如果這個值很高，就可能表示叢集分散很廣。 您應該將此統計資料與叢集中心的平均距離放在一起檢閱，以判斷叢集的散佈。
- 合併評估分數：結果的每個區段底部其會列出該特定模型中所建立叢集的平均分數。


## 模型選擇與評定
- 模型選擇：或稱模型優化，包括同一模型的不同參數調校，以及不同模型的比較。
- 模型評定：未來績效評估，在確定最後模型後，合理地估計其未來實際應用上的績效表現。

以上兩種都需要搭配多種訓練與測試的機制，各種訓練與測試的機制差別在於運用不同的抽樣或重抽樣策略，挑選訓練集、驗證集、測試集。

訓練集：用以建立模型
驗證集：用以調校模型參數，是預測評估模型配適（ fitting） 度及尋找模型參數的方法
測試集：合理估計模型未來績效

### 抽樣方式
- 重抽樣：重抽樣是反覆地從訓練集或資料集中抽出或有不同的各組樣本，並重新配適各組樣本的模型，以獲得模型相關的額外資訊
  - 拔靴抽樣：多次置回的方式，從未被取到的樣本稱為帶外樣本(1/e=約36.8%)
  - k摺交叉檢驗：若 k=10，代表將數據集分成 10 份，將其中 9 份做訓練、 1 份做驗證。相較於他法有較高的變異，但當訓練集大時則此問題較不嚴重
    - 重複的k摺交叉驗證可以有效提高估計的精確度，同時保持小的偏誤，不過計算工作相當沉重
- 保留法：避免使用相同的資料來訓練模型與測試
  - 樣本充足：訓練集、驗證集、測試集
  - 樣本較少時：校驗集(calibration)、測試集
  - 雙重重抽樣，先交叉驗證將資料切割分成校驗集與測試集(外圈重抽樣)；對各校驗集運行交叉驗證進行模型最佳化程序；回到外圈以測驗集估計最佳化模型的績效表現。


#### 練習題
D 15. 模型選擇與評定時，經常運用重抽樣方法進行模型訓練與測試，下列敘述何者正確？
(A) 模型評定（ model assessment） 的工作包括同一模型不同參數的調校（ within model），以及跨越不同模型的比較（ between models）
(B) 模型優化（ model optimization） 的工作則是在確定最優模型後，合理地估計其未來實際應用上可能的績效表現
(C) 與隨機誤差建模相關的參數（ parameters） 有兩種： 一種可以直接利用資料估計其值的超參數（ hyperparameters），另一種則是不易從資料中估計的模型參數
(D) 一般而言 k 摺交叉驗證（ k-fold cross validation） 相較於他法有較高的變異，但當訓練集大時則此問題較不嚴重


143 訓練集與測試集
A 143. 關於訓練資料集與測試資料集，下列敘述何者正確？
(A) 訓練資料是從要分析的資料庫中隨機取樣
(B) 訓練資料可以不知道其類別
(C) 測試資料可以包含訓練資料集中的資料
(D) 測試資料可以不知道其類別


49交叉驗證
B 49. 關於機器學習中的交叉驗證（ Cross-Validation），下列敘述何者正確？
(A) 使用不同架構的模型在相同的資料上，以驗證訓練效果
(B) 是預測評估模型配適（ fitting） 度及尋找模型參數的方法
(C) 用來避免配適不足（ underfitting）
(D) 將資料分割成訓練集（ training set） 跟測試集（ testing set），進行訓練與分析

50模型訓練與測試機制
D 50. 關於模型訓練與測試機制中的資料切分，下列敘述何者「不正確」？
(A) 實務上常用重抽樣法進行模型最佳化
(B) 決定最佳的模型複雜度或參數組合後，最後再以整個校驗集（ calibration set） 建立最佳複雜度或最佳參數組合下的最終模型
(C) 雙重重抽樣法包含內外兩圈的重抽樣機制，分別負責模型最佳化與績效估計的工作，如此內外圈反覆執行所需計算量應是負擔最重的訓練與測試機制
(D) 生醫或化學計量學等領域常因所搜集到樣本通常較少，因而採行50%的訓練集（ training set）用以建立模型， 25%的驗證集（ validationset） 進行模型參數最佳化，以及 25%的測試集（ test set） 測試最終模型等三個子集的切分方式

26重抽樣
D 26. 關於重抽樣方法（ resampling methods），下列敘述何者「不正確」？
(A) 重抽樣是反覆地從訓練集或資料集中抽出或有不同的各組樣本，並重新配適各組樣本的模型，以獲得模型相關的額外資訊
(B) 常用的重抽樣方法有拔靴抽樣法（ bootstrapping）與 k 摺交叉驗證（ k-fold cross validation）
(C) 交叉驗證（ cross validation） 與拔靴抽樣（ bootstrapping） 兩種方法的差別只在於樣本子集如何被挑出
(D) 一般而言 k 摺交叉驗證（ k-fold cross validation） 相較於他法有較低的變異，但當訓練集大時則此問題較不嚴重

C 13. 交叉驗證（ cross-validation） 主要用於模型訓練或建模應用中，目的是為了得到可靠穩定的模型。請問下列敘述何者「 不」 正確？
(A) k 摺交叉驗證（ k-fold cross validation），若 k=10，代表將數據集分成 10 份，將其中 9 份做訓練、 1 份做驗證
(B) 交叉驗證經常用於分類預測、偏最小平方迴歸（ Partial Least Squares regression， PLS 迴歸） 建模等
(C) 採用 k 摺交叉驗證（ k-fold cross validation） 通常會重複 k 次以上， 以 k-1 次的結果均值作為對算法精度的估計
(D) 交叉驗證的類型，常見的有保留法（ holdout） 驗證、 k 摺驗證

A 8. 分類問題當不同類的樣本數不平衡時，下列何者「 不是」 處理方式？
(A) 使用丟棄（ dropout） 方法從大類中剔除一些樣本
(B) 使用降抽樣（ undersampling） 方法從大類中選取部分樣本
(C) 使用權重（ weighting） 方法調整樣本權重
(D) 使用數據合成（ synthetic） 方法生成新的樣本


## 相關與獨立
### 相關性
- 散佈圖矩陣
- 共變異數
- 相關係數
- 共線性、多重共線性
- 皮爾森相關係數

### 獨立統計
- 關聯指標
- 平均列聯係數
- Cramer指數
- 濾網圖
- 馬賽克圖
- 四重圖
- 辛普森悖論



### 分佈類型
25連續型變數
D 25. 下列何者屬於連續型變數資料？
(A) 身分證號
(B) 生日
(C) 血型
(D) 體重


28連續型機率分配
D 28. 統計資料分為離散型與連續型，請問下列何項與其他不同？
(A) 體重
(B) 身高
(C) 成績
(D) 國家數目

29連續型機率分配
D 29. 關於連續型機率分配， 下列敘述何者正確？
(A) 常態分配中， 平均值為 0、 變異數為 0 之分配， 稱為標準常態分配
(B) 已知均勻分配為 U(a, b)，則平均值為(a-b)/2
(C) 伽碼分配是指數分配的特例
(D) 已知隨機變數為標準常態分配，則取其平方為卡方分配且自由度為 1


121 卡方分配、F分配、T分配比較
121. 關於卡方分配、 F 分配、 t 分配之比較，下列敘述何者不正確？
(A) 皆為小樣本
(B) 皆為不連續分配
(C) 三者皆有自由度
(D) 皆來自於常態母體

122 卜瓦松分配
C 122. 關於卜瓦松分配之特性，下列敘述何者不正確？
(A) 某一時段內發生的次數與其他時段發生的次數相互獨立
(B) λ 與所選擇之時間長度成比例
(C) 在極短時間內成功兩次以上之機率不可忽略不計
(D) 在相同長度的時段內發生事件的機率皆相同

124 偏態分佈
B 124. 下圖為海藻資料集的變數 Chla 分佈狀況，請問最接近何種機率分佈？
(A) 常態分佈
(B) 偏態分佈
(C) 幾何分佈
(D) 均勻分佈

171 卡方分配
C 171. 關於卡方分配（ Chi-squared Distribution），下列敘述何者不正確？
(A) 卡方分配的曲線為非對稱的
(B) 卡方分配的期望值為其自由度
(C) 卡方分配的期望值與變異數相等
(D) 卡方分配的自由度越大會使其變異數越大

28機率分配
B 28. 下列敘述何者「不正確」？
(A) 理論上常態分配的平均數=中位數
(B) 機率分配中所有事件機率的總和=期望值
(C) p=0.5 的二項分配為對稱型
(D) 卜瓦松分配中事件發生的最小次數為 0

29常態分佈
C 29. 假設隨機變數 X1、 X2 獨立，且遵從相同的常態分佈 N(μ,σ^2)。若Y=(X1+X2)/2， 請問 Y 遵從的分佈為下列何者？
(A) N(μ,2σ^2)
(B) N(2μ,σ^2)
(C) N(μ,σ^2/2)
(D) N(μ/2,σ^2)
